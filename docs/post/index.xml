<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 镜中人的个人博客</title>
    <link>/travis/post/</link>
    <description>Recent content in Posts on 镜中人的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/travis/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>R模型部署实战</title>
      <link>/travis/2018/07/23/r-model-deployment/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/travis/2018/07/23/r-model-deployment/</guid>
      <description>引言如果此时你对何谓模型部署仍然一无所知的话，不必有任何焦虑的心情，带你入门正是本文的目标所在。请相信我，这篇介绍将会是十分新手友好的，怀着好奇心和耐心读下去，你也会对模型部署建立起清晰的认识。
模型部署是商业情景中的统计建模的极其重要的一部分，然而却往往被人忽视。读完本文，你将了解模型部署的基本概念与用途，并且按照教程学会如何在R环境中使用网络服务(web service)这种形式来部署上线一个模型，更多地，你的方法武器库中将会增添几柄利器: opencpu、fiery及plumbeR。话不多说，Let’s start!
引入模型部署什么是模型部署？一句话概括，模型部署是将一个调试好的模型应用置于生产或者类生产环境中，其意义在于处理预测新数据，为公司提供数据决策或者对接其他需求部门提供模型支持。我们先来看下面这幅数据科学项目开发流程图。
位于图片左边区域中的紫色圆圈中的文字，相信对大部分读者都不陌生。我们在学校中习得了很多关于数据科学模型、特征选择技巧及模型评价方法的知识，回想一下，在你过去大多数课程作业或是打比赛的经历中，完成了模型评价也就意味着项目宣告结束。然而在商业应用中，模型部署才标志着一个项目开发的阶段性结束。它的价值体现在两点：
赋予数据科学模型处理新数据的能力（可以是实时的流数据，或者是积累的批数据）。在实际应用场景中完成模型效果与性能的反馈，为模型调整提供依据，实现建模开发流程的闭环。模型部署的手段1：这里我引述了一些常用的模型部署的手段，接下来我们将会介绍借助R中的网络服务这种形式来搭建一个线上的模型。
各种类型的工件(artifact)这类工件能够将训练好的模型装入一些设备或者终端中，通常在编程语言的均有调用接口。PMML(Predictive Model Markup Language)是其中最常用的一种，它适合应用在实时、大规模数据量的场景。而在深度学习方面，TensorFlow框架提供了模型部署的功能。除此之外还有一些其他的工具，相应的在R中也基本有接口包。
云/服务器这种方式通过在服务器上开启一个服务的方式来部署模型，也是本文着力介绍的。主流的编程语言都有处理网络服务的功能，在python中可以用httpserver、flask、django等搭建网络框架来部署；而R语言做网络服务的包也不止一个，诸如plumber，fiery，opencpu……。“条条大路通罗马”，本文不会对编程语言的选择提供任何建议。
既然是本文重点介绍的方式，不妨多啰嗦两句。
用网络服务做模型部署，将划分出线上与线下两个环境。线下环境是单机环境，用以做一些探索性或者验证性的分析，包含了分析建模的每一个步骤：特征工程、模型选择、模型评价、参数调节……
而线上环境则是生产环境，是把线下调整好参数的模型传至线上对新搜集的数据进行实时反馈。其背后的原理是借助get&amp;amp;post方法把特征字段传递给web服务器，服务器将会用封装好的模型预测并返回参数数值。对get&amp;amp;post不熟悉的可以参考这个教程。
离线部署这种方式相对来说就比较稀松平常了。问离线部署共分几步？答：共分三步。写好模型脚本xx.R或xx.python；把累计的新数据down下来；执行 Rscript xx.R &amp;amp; python xx.python。完事儿~
闲话流数据：前文说到模型部署的一大价值便在于它赋予了数据科学模型处理新数据的能力，而很多新数据通常是实时采集的流式数据。而在我看来，对于流式数据的陌生也是大部分同学在校期间对模型部署接触不多的一大原因，或者与数据采集环节的遥远导致我们把大部分的精力都投入在如何用模型把面前样本数据中的模式挖掘出来。在这种场景下，数据是固定的，被存放在.csv或者各式各样的文件中。
让我们的思路再向前推移一步，用以存放数据的各种数据库或者数据文件是像蓄水池一样逐渐蓄满了被传递进来的数据，而这些数据均是经过一定的技术手段实时采集而来。那么，对于新的观测，一个部署在生产环境中的模型便可以实时地处理预测这些数据：比如互联网金融公司便可根据一个新申请的用户提供的个人信息来预测这名用户的信用评分，垃圾过滤系统也可以获取实时的邮件内容来判断这是否是垃圾邮件。
实战环节得益于Rstudio开发的工具包httpuv，在R语言中处理http以及Websocket请求变成了现实，基于此工具包二次开发的框架opencpu, fiery和plumbeR提供了在线模型部署的R版本的解决方案，下面我们一一介绍：
场景实例：我们演示的场景为垃圾邮件拦截，数据来源自ElemStatLearn包spam数据集。把问题拆解为以下四个步骤来模拟实际生产环境。
根据线下数据训练模型从线上mysql数据库中获取新数据将数据传递至部署在web服务器上的模型并返回预测值使用预测值来决策首先我们进行一些准备工作：
安装所需要的程序包：
for (i in c(&amp;#39;opencpu&amp;#39;,&amp;#39;fiery&amp;#39;,&amp;#39;plumber&amp;#39;,&amp;#39;xgboost&amp;#39;,&amp;#39;glmnet&amp;#39;,&amp;#39;ElemStatLearn&amp;#39;,&amp;#39;RMySQL&amp;#39;)){if (!i %in% installed.packages()) install.packages(i)}使用线下数据训练模型并保存，留待正式部署模型时使用。
library(xgboost)library(glmnet)library(ElemStatLearn)x &amp;lt;- as.</description>
    </item>
    
  </channel>
</rss>